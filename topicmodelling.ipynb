{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification  on Reuters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karchaud\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karchaud\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\karchaud\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xml.sax.saxutils as saxutils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting env variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newsline folder and format\n",
    "data_folder = 'reuters21578/'\n",
    "\n",
    "sgml_number_of_files = 22\n",
    "sgml_file_name_template = 'reut2-NNN.sgm'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it First time only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare documents and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# New experiment\n",
    "\n",
    "# Parse SGML files\n",
    "document_X = {}\n",
    "document_Y = {}\n",
    "\n",
    "df_temp_load = pd.DataFrame(columns=['newid','lewissplit','topic','body'])\n",
    "\n",
    "def strip_tags(text):\n",
    "    return re.sub('<[^<]+?>', '', text).strip()\n",
    "\n",
    "def unescape(text):\n",
    "    return saxutils.unescape(text)\n",
    "\n",
    "numberOfRows = 0\n",
    "# Iterate all files\n",
    "for i in range(sgml_number_of_files):\n",
    "    if i < 10:\n",
    "        seq = '00' + str(i)\n",
    "    else:\n",
    "        seq = '0' + str(i)\n",
    "        \n",
    "    file_name = sgml_file_name_template.replace('NNN', seq)\n",
    "    print('Reading file: %s' % file_name)\n",
    "\n",
    "    with open(data_folder + file_name, 'r') as file:\n",
    "        content = BeautifulSoup(file.read().lower())\n",
    "        \n",
    "        for index, newsline in enumerate(content('reuters')):\n",
    "            document_categories = []\n",
    "            \n",
    "            # News-line Id\n",
    "            document_id = newsline['newid']\n",
    "            lewissplit  =newsline['lewissplit']\n",
    "            # News-line text\n",
    "            document_body = strip_tags(str(newsline('text')[0])).replace('reuter\\n &#3;', '')\n",
    "            document_body = unescape(document_body)\n",
    "            \n",
    "            # News-line categories\n",
    "#            topics = newsline.topics.contents\n",
    "            topics1 = strip_tags(str(newsline.topics.contents))\n",
    "            #print(numberOfRows,  index, '=', numberOfRows + index)\n",
    "            df_temp_load.loc[numberOfRows + index] = [document_id]+  [lewissplit] + [topics1]+ [document_body] \n",
    "        numberOfRows = df_temp_load.index.max() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing raw parsed data in a pickle\n",
    "df_temp_load.to_pickle('ParsedData.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_load.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here second time onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_pickle('ParsedData.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid         21578\n",
       "lewissplit    21578\n",
       "topic         21578\n",
       "body          21578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converting string to list, Column looks like having list but is a string\n",
    "df_temp['topic'] = df_temp['topic'].str.strip('()').str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid         21578\n",
       "lewissplit    21578\n",
       "topic         21578\n",
       "body          21578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newid</th>\n",
       "      <th>lewissplit</th>\n",
       "      <th>topic</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>[[grain,  wheat,  corn,  barley,  oat,  sorghum]]</td>\n",
       "      <td>national average prices for farmer-owned reser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>13799</td>\n",
       "      <td>train</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>national average prices for farmer-owned reser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14485</th>\n",
       "      <td>14486</td>\n",
       "      <td>train</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>national average prices for farmer-owned reser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15951</th>\n",
       "      <td>15952</td>\n",
       "      <td>test</td>\n",
       "      <td>[[grain,  wheat,  corn,  barley,  oat,  sorghum]]</td>\n",
       "      <td>national average prices for farmer-owned reser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       newid lewissplit                                              topic  \\\n",
       "4          5      train  [[grain,  wheat,  corn,  barley,  oat,  sorghum]]   \n",
       "13798  13799      train                                               [[]]   \n",
       "14485  14486      train                                               [[]]   \n",
       "15951  15952       test  [[grain,  wheat,  corn,  barley,  oat,  sorghum]]   \n",
       "\n",
       "                                                    body  \n",
       "4      national average prices for farmer-owned reser...  \n",
       "13798  national average prices for farmer-owned reser...  \n",
       "14485  national average prices for farmer-owned reser...  \n",
       "15951  national average prices for farmer-owned reser...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp[df_temp['body'].str.contains(\"national average prices for \")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting the Topic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp =   df_temp.topic.apply(pd.Series) \\\n",
    "            .merge(df_temp, right_index = True, left_index = True) \\\n",
    "            .drop([\"topic\"], axis = 1) \\\n",
    "            .melt(id_vars = ['newid', 'lewissplit', 'body'], value_name = \"topic\") \\\n",
    "            .drop(\"variable\", axis = 1) \\\n",
    "            .dropna()\n",
    "\n",
    "df_temp['topic'] = df_temp['topic'].str.replace('[','').str.replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newid</th>\n",
       "      <th>lewissplit</th>\n",
       "      <th>body</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>bahia cocoa review\\n    salvador, feb 26 - sho...</td>\n",
       "      <td>cocoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>standard oil &lt;srd&gt; to form financial unit\\n   ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>texas commerce bancshares &lt;tcb&gt; files plan\\n  ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>talking point/bankamerica &lt;bac&gt; equity offer\\n...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>national average prices for farmer-owned reser...</td>\n",
       "      <td>grain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  newid lewissplit                                               body  topic\n",
       "0     1      train  bahia cocoa review\\n    salvador, feb 26 - sho...  cocoa\n",
       "1     2      train  standard oil <srd> to form financial unit\\n   ...       \n",
       "2     3      train  texas commerce bancshares <tcb> files plan\\n  ...       \n",
       "3     4      train  talking point/bankamerica <bac> equity offer\\n...       \n",
       "4     5      train  national average prices for farmer-owned reser...  grain"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "newid         24513\n",
       "lewissplit    24513\n",
       "body          24513\n",
       "topic         24513\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_temp.head())\n",
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid             0\n",
       "lewissplit        0\n",
       "body              1\n",
       "topic         10211\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing blank cells with nan for removing them laters\n",
    "df_temp.replace('',np.nan,inplace=True)\n",
    "df_temp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid         14302\n",
       "lewissplit    14302\n",
       "body          14302\n",
       "topic         14302\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.dropna(inplace=True)\n",
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop word removal\n",
    "df_temp['body'] = df_temp['body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing tag and text between []\n",
    "df_temp['body'] =  [re.sub(\"[\\<\\[].*?[\\>\\]]\",'', str(x)) for x in df_temp['body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remving unwanted characters and punctuations\n",
    "df_temp['body'] = df_temp['body'].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing numbers.\n",
    "df_temp['body'] = df_temp['body'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and Lemmenatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokenized = word_tokenize(text)\n",
    "    no_punc = []\n",
    "    for review in tokenized:\n",
    "        line = \"\".join(char for char in review)\n",
    "        no_punc.append(line)\n",
    "    tokens = lemmatize(no_punc)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    lemma = [lmtzr.lemmatize(t) for t in tokens]\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['body'] = df_temp['body'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid         9656\n",
       "lewissplit    9656\n",
       "body          9656\n",
       "topic         9656\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "newid         3752\n",
       "lewissplit    3752\n",
       "body          3752\n",
       "topic         3752\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train test split based on column lewissplit\n",
    "\n",
    "df_temp['body'] = df_temp['body'].apply(', '.join)\n",
    "train_split= df_temp[df_temp['lewissplit']=='train']\n",
    "test_split= df_temp [df_temp['lewissplit']=='test']\n",
    "display(train_split.count())\n",
    "display(test_split.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newid</th>\n",
       "      <th>lewissplit</th>\n",
       "      <th>body</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237592</th>\n",
       "      <td>235</td>\n",
       "      <td>train</td>\n",
       "      <td>indonesian, agriculture, growth, expected, slo...</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259170</th>\n",
       "      <td>235</td>\n",
       "      <td>train</td>\n",
       "      <td>indonesian, agriculture, growth, expected, slo...</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280748</th>\n",
       "      <td>235</td>\n",
       "      <td>train</td>\n",
       "      <td>indonesian, agriculture, growth, expected, slo...</td>\n",
       "      <td>plywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302326</th>\n",
       "      <td>235</td>\n",
       "      <td>train</td>\n",
       "      <td>indonesian, agriculture, growth, expected, slo...</td>\n",
       "      <td>soy-meal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323904</th>\n",
       "      <td>235</td>\n",
       "      <td>train</td>\n",
       "      <td>indonesian, agriculture, growth, expected, slo...</td>\n",
       "      <td>cotton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       newid lewissplit                                               body  \\\n",
       "237592   235      train  indonesian, agriculture, growth, expected, slo...   \n",
       "259170   235      train  indonesian, agriculture, growth, expected, slo...   \n",
       "280748   235      train  indonesian, agriculture, growth, expected, slo...   \n",
       "302326   235      train  indonesian, agriculture, growth, expected, slo...   \n",
       "323904   235      train  indonesian, agriculture, growth, expected, slo...   \n",
       "\n",
       "            topic  \n",
       "237592     coffee  \n",
       "259170        tea  \n",
       "280748    plywood  \n",
       "302326   soy-meal  \n",
       "323904     cotton  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipeline for grid search with cross validation = 5 and using tf-idf and finding best hyper parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#For all data \n",
    "pipeline = make_pipeline(TfidfVectorizer(min_df=5, norm=None),\n",
    "                     LogisticRegression())\n",
    "tfidf_param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "tfidf_grid = GridSearchCV(pipeline, tfidf_param_grid, cv=5)\n",
    "tfidf_grid.fit(train_split['body'], train_split['topic'])\n",
    "\n",
    "print(\"Best cross-validation score: {:.3f}\".format(tfidf_grid.best_score_))\n",
    "print(\"Best parameters: \", tfidf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ = tfidf_grid.predict(test_split_top10['body'])\n",
    "accuracy_score(test_split['topic'], predict_, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with top 10 frequent topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid         9707\n",
       "lewissplit    9707\n",
       "body          9707\n",
       "topic         9707\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_temp.topic.value_counts().head(10).index.tolist()\n",
    "df_temp_top10 = df_temp[df_temp.topic.isin(x)]\n",
    "df_temp_top10.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid         6721\n",
       "lewissplit    6721\n",
       "body          6721\n",
       "topic         6721\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "newid         2621\n",
       "lewissplit    2621\n",
       "body          2621\n",
       "topic         2621\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_split_top10= df_temp_top10[df_temp_top10['lewissplit']=='train']\n",
    "test_split_top10= df_temp_top10[df_temp_top10['lewissplit']=='test']\n",
    "display(train_split_top10.count())\n",
    "display(test_split_top10.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newid</th>\n",
       "      <th>lewissplit</th>\n",
       "      <th>body</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>national, average, price, farmerowned, reserve...</td>\n",
       "      <td>grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>train</td>\n",
       "      <td>champion, product, approves, stock, split, roc...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>train</td>\n",
       "      <td>computer, terminal, system, completes, sale, c...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>train</td>\n",
       "      <td>cobanco, inc, year, net, santa, cruz, calif, f...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>train</td>\n",
       "      <td>ohio, mattress, may, lower, st, qtr, net, clev...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   newid lewissplit                                               body  topic\n",
       "4      5      train  national, average, price, farmerowned, reserve...  grain\n",
       "8      9      train  champion, product, approves, stock, split, roc...   earn\n",
       "9     10      train  computer, terminal, system, completes, sale, c...    acq\n",
       "10    11      train  cobanco, inc, year, net, santa, cruz, calif, f...   earn\n",
       "11    12      train  ohio, mattress, may, lower, st, qtr, net, clev...   earn"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_top10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karchaud\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.870\n",
      "Best parameters:  {'logisticregression__C': 0.01}\n",
      "accuracy score on test data <function accuracy_score at 0x0000012E31FCF840>\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_top10 = make_pipeline(TfidfVectorizer(min_df=5, norm=None),\n",
    "                     LogisticRegression(multi_class='ovr'))\n",
    "tfidf_param_grid_top10 = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "tfidf_grid_top10 = GridSearchCV(pipeline_top10, tfidf_param_grid_top10, cv=5)\n",
    "tfidf_grid_top10.fit(train_split_top10.body, train_split_top10.topic)\n",
    "\n",
    "print(\"Best cross-validation score: {:.3f}\".format(tfidf_grid_top10.best_score_))\n",
    "print(\"Best parameters: \", tfidf_grid_top10.best_params_)\n",
    "\n",
    "predict_top10 = tfidf_grid_top10.predict(test_split_top10['body'])\n",
    "accuracy_score(test_split_top10['topic'], predict_top10, normalize=True)\n",
    "print('accuracy score on test data',accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_top10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-4c00802ec585>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_top10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline_top10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_split_top10\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline_top10' is not defined"
     ]
    }
   ],
   "source": [
    "predict_top10 = pipeline_top10.predict(test_split_top10['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_top10.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_split_top10['topic'], predict_top10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with top 20 frequent topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid         11104\n",
       "lewissplit    11104\n",
       "body          11104\n",
       "topic         11104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_temp.topic.value_counts().head(20).index.tolist()\n",
    "df_temp_top20 = df_temp[df_temp.topic.isin(x)]\n",
    "df_temp_top20.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newid         7676\n",
       "lewissplit    7676\n",
       "body          7676\n",
       "topic         7676\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "newid         2906\n",
       "lewissplit    2906\n",
       "body          2906\n",
       "topic         2906\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_split_top20= df_temp_top20[df_temp_top20['lewissplit']=='train']\n",
    "test_split_top20= df_temp_top20[df_temp_top20['lewissplit']=='test']\n",
    "display(train_split_top20.count())\n",
    "display(test_split_top20.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karchaud\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\karchaud\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.805\n",
      "Best parameters:  {'logisticregression__C': 0.001}\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_top20 = make_pipeline(TfidfVectorizer(min_df=5, norm=None),\n",
    "                     LogisticRegression())\n",
    "tfidf_param_grid_top20 = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "tfidf_grid_top20 = GridSearchCV(pipeline_top20, tfidf_param_grid_top20, cv=5)\n",
    "tfidf_grid_top20.fit(train_split_top20.body, train_split_top20.topic)\n",
    "\n",
    "print(\"Best cross-validation score: {:.3f}\".format(tfidf_grid_top20.best_score_))\n",
    "print(\"Best parameters: \", tfidf_grid_top20.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_grid_top20' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-5f5074854f69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_top20\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_grid_top20\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_split_top20\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_grid_top20' is not defined"
     ]
    }
   ],
   "source": [
    "predict_top20 = tfidf_grid_top20.predict(test_split_top20['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_split_top20['topic'], predict_top20, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
